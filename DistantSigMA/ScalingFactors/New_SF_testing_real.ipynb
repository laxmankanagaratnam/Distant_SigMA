{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:57:28.669686Z",
     "start_time": "2024-01-17T13:57:19.252423Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "from SigMA.SigMA import SigMA\n",
    "from Loop_functions import setup_ICRS_ps, remove_field_stars, extract_signal_remove_spurious, extract_signal, \\\n",
    "    save_output_summary, consensus_function\n",
    "from IsochroneArchive.myTools import my_utility\n",
    "from PlotlyResults import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def scale_factors(filepath: str, c_solution: int):\n",
    "\n",
    "    if c_solution == 6:\n",
    "        stds = np.genfromtxt(filepath, usecols=(1,2,3), skip_header=2,max_rows=5)\n",
    "    elif c_solution == 4:\n",
    "        stds = np.genfromtxt(filepath, usecols=(1,2,3), skip_header=10, max_rows=5)\n",
    "    else:\n",
    "        print(\"Only 4C and 6C solutions available at the moment\")\n",
    "        stds = None\n",
    "\n",
    "    sfs = np.empty(shape=(5,3))\n",
    "    for h, row in enumerate(stds[:]):\n",
    "        flipped_row = row[::-1]\n",
    "        sfs[h] = 1/flipped_row\n",
    "\n",
    "    return sfs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:57:28.673806Z",
     "start_time": "2024-01-17T13:57:28.671866Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# set sys and output paths\u001B[39;00m\n\u001B[1;32m      2\u001B[0m sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Users/alena/PycharmProjects/Sigma_Orion\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m script_name \u001B[38;5;241m=\u001B[39m my_utility\u001B[38;5;241m.\u001B[39mget_calling_script_name(\u001B[38;5;18;43m__file__\u001B[39;49m)\n\u001B[1;32m      4\u001B[0m output_path \u001B[38;5;241m=\u001B[39m my_utility\u001B[38;5;241m.\u001B[39mset_output_path(main_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Users/alena/Library/CloudStorage/OneDrive-Personal/Work/PhD/Projects/Sigma_Orion/Coding/Code_output/\u001B[39m\u001B[38;5;124m'\u001B[39m, script_name\u001B[38;5;241m=\u001B[39mscript_name)\n",
      "\u001B[0;31mNameError\u001B[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# set sys and output paths\n",
    "sys.path.append('/Users/alena/PycharmProjects/Sigma_Orion')\n",
    "script_name = my_utility.get_calling_script_name(__file__)\n",
    "output_path = my_utility.set_output_path(main_path='/Users/alena/Library/CloudStorage/OneDrive-Personal/Work/PhD/Projects/Sigma_Orion/Coding/Code_output/', script_name=script_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-17T13:57:29.050769Z",
     "start_time": "2024-01-17T13:57:28.674621Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "region = 0.0\n",
    "run = 2\n",
    "\n",
    "df_load = pd.read_csv(\"/Users/alena/PycharmProjects/SigMA_Orion/Start_data/Orion_labeled_segments_KNN_300_15-11-23.csv\")\n",
    "df_region = df_load[df_load.region == region]\n",
    "result_path = output_path + f\"Run_{run}/Region_{int(region)}/\"\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define fixed SigMA parameters\n",
    "step = 2\n",
    "alpha = 0.05\n",
    "beta = 0.99\n",
    "knn_initcluster_graph = 35\n",
    "knn = 30\n",
    "bh = False\n",
    "n_resampling = 0\n",
    "scaling = None\n",
    "\n",
    "feature_space = ['ra', 'dec', 'plx', 'pmra', 'pmdec']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "std_path = \"/Users/alena/PycharmProjects/SigMA_Orion/Start_data/Region_0/simulated_sfs.txt\"\n",
    "ra_scaling, dec_scaling, plx_scaling, pmra_scaling, pmdec_scaling = scale_factors(std_path, 6)\n",
    "pmdec_new = pmdec_scaling[1:]\n",
    "pmra_new = pmra_scaling[:2]\n",
    "# create the 243 possible combinations\n",
    "combinations = np.array(list(product(ra_scaling, dec_scaling, plx_scaling, pmra_new, pmdec_new)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "sampled_rows = np.random.choice(combinations.shape[0], size=108, replace=False)\n",
    "\n",
    "# Use the sampled rows to extract the corresponding entries\n",
    "sampled_entries = combinations[sampled_rows]\n",
    "# Calculate the mean of each column\n",
    "column_means = np.mean(sampled_entries, axis=0)\n",
    "\n",
    "# Print or use the column means\n",
    "print(column_means)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_region.rename(columns={\"parallax\": \"plx\"}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --------------------- Evaluate sampled gps ---------------------\n",
    "# initialize SigMA for computational efficiency\n",
    "setup_kwargs, df_focus = setup_ICRS_ps(df_fit=df_region, sf_params=['ra', 'dec', 'plx'],\n",
    "                                       sf_range=[ra_scaling, dec_scaling, plx_scaling], KNN_list=[knn], beta=beta,\n",
    "                                       knn_initcluster_graph=knn_initcluster_graph, scaling=scaling)\n",
    "sigma_kwargs = setup_kwargs[\"sigma_kwargs\"]\n",
    "scale_factor_list = setup_kwargs[\"scale_factor_list\"]\n",
    "clusterer = SigMA(\n",
    "    data=df_focus, **sigma_kwargs)\n",
    "\n",
    "# set mean of sampled list as SF\n",
    "scale_factors = {'pos': {'features': ['ra', 'dec', 'plx'], 'factor': list(column_means[:3])},\n",
    "                 'vel': {'features': ['pmra', 'pmdec'], 'factor': list(column_means[3:])}}\n",
    "clusterer.set_scaling_factors(scale_factors)\n",
    "print(clusterer.scale_factors)\n",
    "# save X_mean\n",
    "X_mean_sf = clusterer.X\n",
    "\n",
    "label_matrix_rfs = np.empty(shape=(len(sampled_rows), len(df_focus)))\n",
    "label_matrix_rsc = np.empty(shape=(len(sampled_rows), len(df_focus)))\n",
    "label_matrix_simple = np.empty(shape=(len(sampled_rows), len(df_focus)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --------------------- Loop ---------------------\n",
    "outer = np.empty(shape=(1, 3))\n",
    "# outer_names = []\n",
    "rho_sum = np.zeros(df_focus.shape[0], dtype=np.float32)\n",
    "\n",
    "# Evaluate every grid point of the sample\n",
    "for j, combo in enumerate(sampled_entries[:]):\n",
    "    print(f\"--- Gridpoint {j} ---\")\n",
    "\n",
    "    scale_factors = {'pos': {'features': ['ra', 'dec', 'plx'], 'factor': list(combo[:3])},\n",
    "                     'vel': {'features': ['pmra', 'pmdec'], 'factor': list(combo[3:])}}\n",
    "    #                 'vel': {'features': ['pmra', 'pmdec'], 'factor': [0.5,0.5]}}\n",
    "    clusterer.set_scaling_factors(scale_factors)\n",
    "    print(f\"Performing clustering for scale factor {clusterer.scale_factors['pos']['factor']}, {clusterer.scale_factors['vel']['factor']}...\")\n",
    "\n",
    "    # Fit\n",
    "    clusterer.fit(alpha=alpha, knn=knn, bh_correction=bh)\n",
    "    label_array = clusterer.labels_\n",
    "    # density and X\n",
    "    rho, X = clusterer.weights_, clusterer.X\n",
    "    rho_sum += rho\n",
    "\n",
    "    # a) remove field stars\n",
    "    nb_rfs = remove_field_stars(label_array, rho, label_matrix_rfs, j)\n",
    "    # b) remove spurious clusters\n",
    "    nb_es, nb_rsc = extract_signal_remove_spurious(df_focus, label_array, rho, X, label_matrix_rsc, j)\n",
    "    # c) extract signal\n",
    "    nb_simple = extract_signal(label_array, clusterer, label_matrix_simple, j)\n",
    "\n",
    "    labels_rsc = label_matrix_rsc[j, :].reshape(label_matrix_rsc.shape[1], )\n",
    "    labels_rfs = label_matrix_rfs[j, :].reshape(label_matrix_rfs.shape[1], )\n",
    "    labels_simple = label_matrix_simple[j, :].reshape(label_matrix_simple.shape[1], )\n",
    "\n",
    "# Perform consensus clustering on the a) and b) arrays (automatically generates and saves a html-plot)\n",
    "df_save = df_focus\n",
    "label_lists = [label_matrix_rfs, label_matrix_rsc, label_matrix_simple]\n",
    "\n",
    "# Perform consensus clustering on the c) and d) steps\n",
    "labels_cc, n_cc = zip(\n",
    "    *(consensus_function(jl, rho_sum, df_focus, f\"Run_{run}_real_{name}_CC\",\n",
    "                         output_path, plotting=False) for jl, name in zip(label_lists, [\"rfs\", \"rsc\", \"simple\"])))\n",
    "n_occ = list(n_cc)\n",
    "labels_occ = list(labels_cc)\n",
    "\n",
    "names = [\"rfs\", \"rsc\", \"new\"]\n",
    "for i, entry in enumerate(labels_occ):\n",
    "    plot(entry, df_focus, f\"Run_{run}_{names[i]}\", output_path, icrs=True, return_fig=False)\n",
    "\n",
    "\n",
    "save_output_summary(\n",
    "    summary_str={\"run\": run, \"knn\": knn,\n",
    "                 \"n_rfs\": n_occ[0], \"n_rsc\": n_occ[1], \"n_new\": n_occ[2]},\n",
    "    file=output_path + f\"summary_run_{run}_real_CC.csv\")\n",
    "\n",
    "# save the labels in a csv file and plot the result\n",
    "df_save[\"rsc\"] = labels_occ[1]\n",
    "df_save[\"rfs\"] = labels_occ[0]\n",
    "df_save[\"simple\"] = labels_occ[2]\n",
    "df_save.to_csv(output_path + f\"Run_{run}_results_CC.csv\")\n",
    "\n",
    "\n",
    "outer[0,:] = [(len(np.unique(i)) - 1) for i in labels_occ]\n",
    "summary_df = pd.DataFrame(data=outer, columns=[\"n_rfs\", \"n_rsc\", \"n_new\"])\n",
    "summary_df.to_csv(output_path + f\"{run}_real_knn_{knn}_bh_{bh}_summary.csv\")\n",
    "\n",
    "##########\n",
    "# Output log-file\n",
    "all_fixed = {\"step\": step, \"alpha\": alpha, \"beta\": beta, \"knn_initcluster_graph\": knn_initcluster_graph,\n",
    "             \"KNN\": knn, \"sfs_list\": f\"cc_{len(sampled_rows)}_seed_{seed_value}\", \"scaling\": scaling, \"bh_correction\":\n",
    "                 bh}\n",
    "\n",
    "filename = output_path + f\"Parameters_run_{run}.txt\"\n",
    "with open(filename, 'w') as file:\n",
    "    for key, value in all_fixed.items():\n",
    "        file.write(f\"{key} = {value}\\n\")\n",
    "###########\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
